{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4721b-e1c4-4f82-a3d6-7c8ab4a1d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in background\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# IKEA category URL (example: Chairs)\n",
    "IKEA_URL = \"https://www.ikea.com/us/en/cat/chairs-fu002/\"\n",
    "\n",
    "def scrape_ikea_products():\n",
    "    driver.get(IKEA_URL)\n",
    "    time.sleep(5)  # Allow page to load\n",
    "\n",
    "    # Scroll down multiple times to load more products\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # 🛠 **Updated Selector** - Try grabbing product cards\n",
    "    products = []\n",
    "    items = driver.find_elements(By.CSS_SELECTOR, \"[data-ref-id]\")  # Finds all product containers\n",
    "\n",
    "    for item in items:\n",
    "        try:\n",
    "            name = item.find_element(By.CSS_SELECTOR, \"span:not([class])\").text  # Find first <span> with text\n",
    "            price = item.find_element(By.CSS_SELECTOR, \"span.pip-price__integer\").text\n",
    "            image = item.find_element(By.CSS_SELECTOR, \"img\").get_attribute(\"src\")\n",
    "            link = item.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "\n",
    "            products.append({\"Name\": name, \"Price\": price, \"Image URL\": image, \"Link\": link})\n",
    "        except Exception as e:\n",
    "            print(\"Skipping product due to error:\", e)\n",
    "            continue\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame(products)\n",
    "    df.to_csv(\"ikea_products.csv\", index=False)\n",
    "    print(f\"✅ Scraped {len(products)} products and saved to 'ikea_products.csv'.\")\n",
    "\n",
    "scrape_ikea_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aacc68-02b1-48d8-87cd-02d1b77d989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in background\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# IKEA Categories\n",
    "ikea_categories = {\n",
    "    \"Chairs\": \"https://www.ikea.com/us/en/cat/chairs-fu002/\",\n",
    "    \"Sofas\": \"https://www.ikea.com/us/en/cat/sofas-sectionals-fu003/\",\n",
    "    \"Tables\": \"https://www.ikea.com/us/en/cat/tables-desks-fu004/\",\n",
    "    \"Beds\": \"https://www.ikea.com/us/en/cat/beds-mattresses-fu005/\",\n",
    "    \"Storage\": \"https://www.ikea.com/us/en/cat/storage-organization-fu006/\",\n",
    "    \"Lighting\": \"https://www.ikea.com/us/en/cat/lighting-fu007/\"\n",
    "}\n",
    "\n",
    "all_products = []  # Store all scraped products\n",
    "\n",
    "def scrape_ikea_category(category_name, url):\n",
    "    print(f\"🔄 Scraping {category_name}...\")\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Allow page to load\n",
    "\n",
    "    # Scroll down to load all products\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extract product details\n",
    "    items = driver.find_elements(By.CSS_SELECTOR, \"[data-ref-id]\")\n",
    "    category_products = []\n",
    "\n",
    "    for item in items:\n",
    "        try:\n",
    "            name = item.find_element(By.CSS_SELECTOR, \"span:not([class])\").text  # Product name\n",
    "            price = item.find_element(By.CSS_SELECTOR, \"span.pip-price__integer\").text  # Price\n",
    "            image = item.find_element(By.CSS_SELECTOR, \"img\").get_attribute(\"src\")  # Image URL\n",
    "            link = item.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")  # Product link\n",
    "\n",
    "            category_products.append({\"Category\": category_name, \"Name\": name, \"Price\": price, \"Image URL\": image, \"Link\": link})\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(f\"✅ Scraped {len(category_products)} products from {category_name}.\")\n",
    "    return category_products\n",
    "\n",
    "# Loop through each category and scrape\n",
    "for category, url in ikea_categories.items():\n",
    "    all_products.extend(scrape_ikea_category(category, url))\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Save all data to CSV\n",
    "df = pd.DataFrame(all_products)\n",
    "df.to_csv(\"ikea_all_products.csv\", index=False)\n",
    "print(f\"🎉 Scraped {len(all_products)} total products and saved to 'ikea_all_products.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c7a850-fe8d-4329-a8a7-04ac394a2b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# IKEA Regions\n",
    "ikea_regions = {\n",
    "    \"USA\": \"https://www.ikea.com/us/en/\",\n",
    "    \"UK\": \"https://www.ikea.com/gb/en/\",\n",
    "    \"Germany\": \"https://www.ikea.com/de/de/\",\n",
    "    \"France\": \"https://www.ikea.com/fr/fr/\",\n",
    "    \"Canada\": \"https://www.ikea.com/ca/en/\",\n",
    "    \"Australia\": \"https://www.ikea.com/au/en/\"\n",
    "}\n",
    "\n",
    "# IKEA Categories\n",
    "ikea_categories = {\n",
    "    \"Chairs\": \"cat/chairs-fu002/\",\n",
    "    \"Sofas\": \"cat/sofas-sectionals-fu003/\",\n",
    "    \"Tables\": \"cat/tables-desks-fu004/\",\n",
    "    \"Beds\": \"cat/beds-mattresses-fu005/\",\n",
    "    \"Storage\": \"cat/storage-organization-fu006/\",\n",
    "    \"Lighting\": \"cat/lighting-fu007/\"\n",
    "}\n",
    "\n",
    "all_products = []  # Store all scraped products\n",
    "\n",
    "def scrape_ikea_category(region, base_url, category_name, category_url):\n",
    "    \"\"\" Starts a new Chrome session for each region to prevent session loss. \"\"\"\n",
    "    \n",
    "    # Start a NEW browser session each time\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run in background\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\")\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    \n",
    "    full_url = base_url + category_url\n",
    "    print(f\"🔄 Scraping {category_name} from {region} - {full_url}\")\n",
    "    driver.get(full_url)\n",
    "    time.sleep(5)  # Allow page to load\n",
    "\n",
    "    # Scroll to load all products\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extract product details\n",
    "    items = driver.find_elements(By.CSS_SELECTOR, \"[data-ref-id]\")\n",
    "    category_products = []\n",
    "\n",
    "    for item in items:\n",
    "        try:\n",
    "            name = item.find_element(By.CSS_SELECTOR, \"span:not([class])\").text\n",
    "            price = item.find_element(By.CSS_SELECTOR, \"span.pip-price__integer\").text\n",
    "            image = item.find_element(By.CSS_SELECTOR, \"img\").get_attribute(\"src\")\n",
    "            link = item.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "\n",
    "            category_products.append({\n",
    "                \"Region\": region,\n",
    "                \"Category\": category_name,\n",
    "                \"Name\": name,\n",
    "                \"Price\": price,\n",
    "                \"Image URL\": image,\n",
    "                \"Link\": link\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(f\"✅ Scraped {len(category_products)} products from {category_name} in {region}.\")\n",
    "    \n",
    "    driver.quit()  # Close browser session\n",
    "    return category_products\n",
    "\n",
    "# Loop through each region and category (Restarting Browser Each Time)\n",
    "for region, base_url in ikea_regions.items():\n",
    "    for category, category_url in ikea_categories.items():\n",
    "        all_products.extend(scrape_ikea_category(region, base_url, category, category_url))\n",
    "\n",
    "# Save all data to CSV\n",
    "df = pd.DataFrame(all_products)\n",
    "df.to_csv(\"ikea_all_regions.csv\", index=False)\n",
    "print(f\"🎉 Scraped {len(all_products)} total products from multiple regions and saved to 'ikea_all_regions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3928e-fc86-4f17-9476-02d4e08bd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Load product data\n",
    "df = pd.read_csv(\"ikea_all_regions.csv\")\n",
    "\n",
    "# Create folder for images\n",
    "IMAGE_FOLDER = \"ikea_images\"\n",
    "os.makedirs(IMAGE_FOLDER, exist_ok=True)\n",
    "\n",
    "# Download images\n",
    "for index, row in df.iterrows():\n",
    "    image_url = row[\"Image URL\"]\n",
    "    \n",
    "    # 🛠 Handle missing product names\n",
    "    product_name = str(row[\"Name\"])  # Convert to string to avoid float issues\n",
    "    if pd.isna(product_name) or product_name.strip() == \"nan\":  \n",
    "        product_name = f\"product_{index}\"  # Use a default name\n",
    "\n",
    "    product_name = product_name.replace(\"/\", \"-\").replace(\"\\\\\", \"-\")[:50]  # Clean filename\n",
    "    image_path = f\"{IMAGE_FOLDER}/{product_name}_{index}.jpg\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(image_url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            with open(image_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"✅ Downloaded: {product_name}\")\n",
    "        else:\n",
    "            print(f\"❌ Failed to download: {product_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error downloading {product_name}: {e}\")\n",
    "\n",
    "print(\"🎉 All images downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accbf1b7-edcd-498b-8fea-a03727e6c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Load CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Load IKEA product data\n",
    "df = pd.read_csv(\"ikea_all_regions.csv\")\n",
    "\n",
    "# Create a list to store embeddings\n",
    "image_embeddings = []\n",
    "image_paths = []\n",
    "\n",
    "# Define image folder\n",
    "IMAGE_FOLDER = \"ikea_images\"\n",
    "\n",
    "# Process each image\n",
    "for index, row in df.iterrows():\n",
    "    image_name = str(row[\"Name\"]).replace(\"/\", \"-\").replace(\"\\\\\", \"-\")[:50]\n",
    "    image_path = f\"{IMAGE_FOLDER}/{image_name}_{index}.jpg\"\n",
    "    \n",
    "    if os.path.exists(image_path):\n",
    "        try:\n",
    "            image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                embedding = model.encode_image(image).cpu().numpy()\n",
    "            image_embeddings.append(embedding)\n",
    "            image_paths.append(image_path)\n",
    "            print(f\"✅ Processed {image_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing {image_name}: {e}\")\n",
    "\n",
    "# Convert embeddings to NumPy array\n",
    "image_embeddings = np.vstack(image_embeddings)\n",
    "\n",
    "# Save embeddings using FAISS for fast search\n",
    "faiss_index = faiss.IndexFlatL2(image_embeddings.shape[1])\n",
    "faiss_index.add(image_embeddings)\n",
    "\n",
    "faiss.write_index(faiss_index, \"ikea_clip_index.faiss\")\n",
    "np.save(\"ikea_image_paths.npy\", image_paths)\n",
    "\n",
    "print(\"🎉 CLIP embeddings saved! Now we can search IKEA images using text or images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6947142f-fa3a-48c9-ac0d-0a456eb1f354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa6036-8c8d-419f-966b-a840c9069c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b072da-af0c-4c6b-b3a4-249c72eba67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdbb544-2e5b-4c87-ac81-6739b5f45df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
